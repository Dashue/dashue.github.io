<rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Johan Nilssons blog</title><link>http://www.johanilsson.com/feed.xml</link><description>Johan Nilssons blog</description><item><guid isPermaLink="true">http://www.johanilsson.com/2014/10/net_memory_management_101/</guid><link>http://www.johanilsson.com/2014/10/net_memory_management_101/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>GC</category><category>Memory</category><title>.Net Memory Management 101</title><description>&lt;p&gt;A brieft explanation of memory management and garbage collection in .net&lt;/p&gt;
</description><pubDate>Fri, 10 Oct 2014 23:00:00 Z</pubDate><a10:updated>2014-10-10T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;I recently viewed a video about a memory profiling product from Jetbrains: dotmemory 4. To get everyone on the same level, Maarten Balliauw provided a brief explanation to memory management and garbage collection in .Net.&lt;/p&gt;

&lt;p&gt;I thought the explanation was clear and spot on and this post is intended to recapture it for future references.&lt;/p&gt;

&lt;p&gt;With this only being the notes from his talk, I recommend the reader to view the video for the full explanation.&lt;/p&gt;

&lt;p&gt;The video can be found here &lt;a href="http://youtu.be/1lqfxl8AJR0"&gt;"DotMemory 4: What's new?"&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Content&lt;/h2&gt;

&lt;h3&gt;Memory Allocation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;.Net runtime reserves a region of address space for every new process called the &lt;em&gt;"managed heap"&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Objects are allocated in the heap&lt;/li&gt;
&lt;li&gt;Allocating memory is fast, it's just adding a pointer&lt;/li&gt;
&lt;li&gt;Some unmanaged memory is also consumed and will not be collected &lt;em&gt;(.NET CLR, Dynamic libraries, Graphics buffer and more)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Memory Release aka "Garbage Collection" (GC)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Releases objects no longer in use by examining application roots&lt;/li&gt;
&lt;li&gt;Builds a graph that contains all objects that are reachable from these roots&lt;/li&gt;
&lt;li&gt;Removes the object from the heap (releases memory) if it is not reachable from the graph&lt;/li&gt;
&lt;li&gt;Compacts reachable objects in memory&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Generations&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Managed heap is divided into three segments called &lt;em&gt;"generations"&lt;/em&gt; or &lt;em&gt;"gen"&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;New objects go into Gen 0&lt;/li&gt;
&lt;li&gt;Gen 0: Short-lived objects (e.g Local variables)&lt;/li&gt;
&lt;li&gt;Gen 1: In-between objects&lt;/li&gt;
&lt;li&gt;Gen 2: Long-lived objects (e.g App main, form, static)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Memory release implementation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;When Gen 0 is full
&lt;ul&gt;
&lt;li&gt;Perform GC on Gen 0&lt;/li&gt;
&lt;li&gt;Promote reachable objects to Gen 1&lt;/li&gt;
&lt;li&gt;This is typically pretty fast&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;When Gen 1 is full
&lt;ul&gt;
&lt;li&gt;Perform GC on Gen 1 and Gen 0&lt;/li&gt;
&lt;li&gt;Promoted rechable object to Gen 2&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;When Gen 2 is full
&lt;ul&gt;
&lt;li&gt;Perform "&lt;em&gt;Full GC&lt;/em&gt;" (2, 1, 0)&lt;/li&gt;
&lt;li&gt;Throws &lt;em&gt;OutOfMemoryException&lt;/em&gt; if not enough memory exists for new allocations&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Full GC&lt;/em&gt; has a performance impact, since all objects in the managed heap are verified, not just objects reachable from graph.&lt;/p&gt;

&lt;h3&gt;Large Object Heap "LOH"&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Separate segment within the managed heap&lt;/li&gt;
&lt;li&gt;Large objects &gt;85kb&lt;/li&gt;
&lt;li&gt;Only collected during &lt;em&gt;Full GC&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;LOH&lt;/em&gt; is not compacted and becomes fragmented over time. This fragmentation will cause &lt;em&gt;OutOfMemoryException&lt;/em&gt; if there is not enough free space for new objects.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/09/typescript_only_allowed_to_reference_ts_files/</guid><link>http://www.johanilsson.com/2014/09/typescript_only_allowed_to_reference_ts_files/</link><a10:author><a10:name /></a10:author><category>Javascript</category><category>Typescript</category><title>Only files with a .ts extension are allowed</title><description>&lt;p&gt;After encountering this issue multiple times, and each time thinking "This should have a blog post for the next time it's encountered". After what felt like 5 encounters, it was finally time to blog about this.&lt;/p&gt;
</description><pubDate>Sat, 13 Sep 2014 23:00:00 Z</pubDate><a10:updated>2014-09-13T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;The times this issue have been encountered has been when trying to reference a third party javascript library in a typescript file. Upon compilation the following error is presented: &lt;em&gt;"Incorrect reference: Only files with a .ts extension are allowed"&lt;/em&gt; and typescript will not budge until it is fixed.&lt;/p&gt;

&lt;h2&gt;Solution&lt;/h2&gt;

&lt;p&gt;One solution is to put an empty declaration in the relevant Typescript file, reflecting the functionality of library. This satisfies the typescript compiler and allows the compilation to complete.&lt;/p&gt;

&lt;h3&gt;An example:&lt;/h3&gt;

&lt;p&gt;Using the library with which this issue was last encountered: &lt;em&gt;LogEntries&lt;/em&gt;. The basic functionality of LogEntries is comprised of two methods: &lt;em&gt;init&lt;/em&gt; and &lt;em&gt;log&lt;/em&gt;. The empty declaration would be the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;declare class LE
{
    public static init(token: string);
    public static log(message: string);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After that there should be no complaints from the Typescript compiler.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/07/a-study-in-garbage-collection/</guid><link>http://www.johanilsson.com/2014/07/a-study-in-garbage-collection/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>GC</category><category>Study</category><title>A study in garbage collection</title><description>&lt;p&gt;My notes from Johanathan Worthington's GC talk at "Build Stuff 13"&lt;/p&gt;
</description><pubDate>Sat, 05 Jul 2014 23:00:00 Z</pubDate><a10:updated>2014-07-05T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;For some time I've been meaning to further my understanding of Garbage Collection and the .Net CLR Garbage Collector. The recording of Jonathan Worthington's presentation &lt;a href="http://www.infoq.com/presentations/terminology-garbage-collector"&gt;"The Secret Lives of Garbage Collectors"&lt;/a&gt; at BuildStuff 13, provided the perfect opportunity. Jonathan is knowledgeable and a fun to listen to, so if you haven't checked this presentation out, I recommend you to do so.&lt;/p&gt;

&lt;p&gt;These are my notes, intended for my future self. &lt;/p&gt;

&lt;h2&gt;Terminology&lt;/h2&gt;

&lt;h3&gt;GC Roots&lt;/h3&gt;

&lt;p&gt;Active Roots kept track of by JIT. &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Static variables&lt;/li&gt;
&lt;li&gt;Local variables.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Reachability Analysis&lt;/h3&gt;

&lt;p&gt;Produces a slight overestimate of what objects are available&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start at roots&lt;/li&gt;
&lt;li&gt;Traverse everything reachable from the roots 
&lt;ul&gt;
&lt;li&gt;Local variables&lt;/li&gt;
&lt;li&gt;Static variables&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We know that everything that isn't reachable, cannot be used by the progam and can be collected.&lt;/p&gt;

&lt;h3&gt;Write barrier&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Triggered everytime you write a pointer into an object&lt;/li&gt;
&lt;li&gt;Takes the object about to be updated, inspects the pointer its about to write, checks wether the object exist in an older generation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If the object exists in an older generation&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It's stored into a "remembered set" (objects in a younger generation referenced from an older generation)&lt;/li&gt;
&lt;li&gt;Eventually objects in the younger generation will be moved to an older generation and will then be removed from the remembered set.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Leveraging a remembered set is cheaper than checking the older generations on every collection&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;Collectors&lt;/h2&gt;

&lt;h3&gt;Conservative GC&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Walks through the stack and looks at everything.&lt;/li&gt;
&lt;li&gt;False positives&lt;/li&gt;
&lt;li&gt;Performs awfully&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Precise GC&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Knows where everything is, objects and pointers to them&lt;/li&gt;
&lt;li&gt;Makes stack maps when jitting&lt;/li&gt;
&lt;li&gt;Allows to move objects around (alot of GC do this)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Two versions of collectors&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Compaction
Used my most collector &lt;/li&gt;
&lt;li&gt;Copying&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Implementations&lt;/h2&gt;

&lt;h3&gt;Generational Collectors&lt;/h3&gt;

&lt;p&gt;A generationl collector divides objects into generations 2-3 normally. Objects are segregated by age. This works because of &lt;em&gt;"The Generational Hyphotesis"&lt;/em&gt;. &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The majority of objects in a program, live for a very very short time, or for the whole application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Starts by allocating objects into the young generation Gen 0&lt;/li&gt;
&lt;li&gt;If an object survives certain amounts of gc, the object has a longer life time becomes promoted to old generation
&lt;ul&gt;
&lt;li&gt;Allows us to only consider young generations in the majority of garbage collections. &lt;/li&gt;
&lt;li&gt;It ignores any pointed to an object in the older generation&lt;/li&gt;
&lt;li&gt;The young generation stays fairly small, megabytes at each time&lt;/li&gt;
&lt;li&gt;Full collects happen less often, it then considers all of the generations.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Comes with a problem:&lt;/strong&gt; What happens if the only way an object in the young generation is reachable, is through a pointer from and object in an older generation? If the garbage collecton only considers the young generation, it will think this new object is not referenced, and will free it. This happends when a new item is added to an older list.&lt;/p&gt;

&lt;p&gt;This is solved using what is called a &lt;em&gt;"Write barrier"&lt;/em&gt;, every time an assignment ( = ) is made, objects need to be inspected and any relations in pointers inbetween generations is stored.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt; Can use different algorithms for different generations.&lt;/p&gt;

&lt;h2&gt;Noteworthy&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Garbage collection can be triggered by anything that can allocate&lt;/li&gt;
&lt;li&gt;GC is moving objects in memory around as your program run&lt;/li&gt;
&lt;li&gt;C# structs are good to know (does not allow stack location)&lt;/li&gt;
&lt;li&gt;Lots ot LOB can hurt (triggering garbage collection)&lt;/li&gt;
&lt;li&gt;Precise lists (prevents resize and performs better)&lt;/li&gt;
&lt;li&gt;Finalizers 
&lt;ul&gt;
&lt;li&gt;might bring the object alive&lt;/li&gt;
&lt;li&gt;always make object live longer than necessary&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The CLR Has two different Garbage Collectors
&lt;ul&gt;
&lt;li&gt;Client - Concurrent (keeps pause times down)&lt;/li&gt;
&lt;li&gt;Server - (keeps Throughput rate high)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/07/typescript-not-compiling-on-build/</guid><link>http://www.johanilsson.com/2014/07/typescript-not-compiling-on-build/</link><a10:author><a10:name /></a10:author><category>Typescript</category><title>Typescript not compiling on build</title><description>&lt;p&gt;The solution for an issue where typescript was not compiling on build.&lt;/p&gt;
</description><pubDate>Tue, 01 Jul 2014 23:00:00 Z</pubDate><a10:updated>2014-07-01T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;I encountered an issue where typescript was not compiling during the build phase of a project. Typescript was however compiling when files where saved, and although errors when saving wouldn't fail the build, they would show up in the "Error List".&lt;/p&gt;

&lt;h2&gt;Solution&lt;/h2&gt;

&lt;p&gt;It turns out that the order of how you import build targets matters. The import of &lt;em&gt;Microsoft.TypeScript.targets&lt;/em&gt; must come after &lt;em&gt;Microsoft.CSharp.targets&lt;/em&gt; and the following resolved the issue.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.johanilsson.com/images/2014-07-02.png" alt="Solution" /&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/06/camelcase-when-json-serializing-from-propercase/</guid><link>http://www.johanilsson.com/2014/06/camelcase-when-json-serializing-from-propercase/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>Json.Net</category><category>NancyFx</category><title>camelCase when json serializing from ProperCase</title><description>&lt;p&gt;Follow naming conventions by &lt;em&gt;camelCasing&lt;/em&gt; when serializing &lt;em&gt;ProperCase&lt;/em&gt;&lt;/p&gt;
</description><pubDate>Fri, 13 Jun 2014 23:00:00 Z</pubDate><a10:updated>2014-06-13T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;To set the scene: I have a backend written in C# and a front-end written in Javascript. C# proposes &lt;em&gt;ProperCase&lt;/em&gt; and Javascript propses &lt;em&gt;camelCase&lt;/em&gt; naming convention. Now the issue is that by default Json.Net serializes the data using the same casing as the type being serialized from, leaving us in a situation where we return &lt;em&gt;ProperCase&lt;/em&gt; serialized data to a solution that throughout uses a different casing. To avoid having a solution mixing conventions and to avoid having to remember which portion uses which convention, we want to serialize to the expected one.&lt;/p&gt;

&lt;h2&gt;Solution&lt;/h2&gt;

&lt;p&gt;As with any problems there are many solutions, ranging from putting json attributes on your model specifying property names, creating a new model with propertynames following the expected covention (but breaking c# convention), using anonymous types with the right casing, or tweak your serialize.&lt;/p&gt;

&lt;p&gt;I chose to tweak my serailizer to use 'camelCase' for all json data and as always with anything NancyFx related, the solution was very simple (2 steps).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; Create a customized serializer:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class CustomJsonSerializer : JsonSerializer
{
    public CustomJsonSerializer()
    {
        ContractResolver = new CamelCasePropertyNamesContractResolver();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; Register it in NancyFx using the Ioc container of your choice (This exmple uses Ninject).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;protected override void ConfigureApplicationContainer(IKernel kernel)
{
    kernel.Bind&amp;lt;JsonSerializer&amp;gt;().To&amp;lt;CustomJsonSerializer&amp;gt;();
}
&lt;/code&gt;&lt;/pre&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/05/a-little-gem-called-hashset/</guid><link>http://www.johanilsson.com/2014/05/a-little-gem-called-hashset/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>A little gem called Hashset</title><description>&lt;p&gt;Showing one scenario where Hashset is more appropriate than Dictionary&lt;/p&gt;
</description><pubDate>Wed, 30 Apr 2014 23:00:00 Z</pubDate><a10:updated>2014-04-30T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;Every know and then I stumble upon the Dictionary being used for keeping track of uniqueness. One example usage I recently encountered was keeping identifying weather a message had been published already, alternatively had been received by the subscriber.&lt;/p&gt;

&lt;p&gt;An example of how this would look using Dictionary:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var dictionary = new Dictionary&amp;lt;TKey, bool&amp;gt;();
if(false == dictionary.ContainsKey(key))
{
    // Mark identifier as handled
    dictionary.Add(key, true);

    // Do stuff
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case the Dictionary allows for an unnecessary extra dimension in the form of a &lt;strong&gt;Value&lt;/strong&gt;. If the key exists, we could assume it has been handled.&lt;/p&gt;

&lt;h2&gt;HashSet&lt;/h2&gt;

&lt;p&gt;There there is an even more appropriate data structure, and a surprisingly large group of people haven't heard about it, called HashSet. A HashSet is like a Dictionary without the Value dimension, just the key/identifier portion.&lt;/p&gt;

&lt;p&gt;HashSet has a method with the signature of bool Add(TKey), which will try to add the identifier and return a boolean wether it already existed or not.&lt;/p&gt;

&lt;p&gt;An example of how this would look:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var hashSet = new HashSet&amp;lt;TIdentifier&amp;gt;();
if(hashSet.Add(identifier)
{
    // Actions to take on identifier not yet handled
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;Even though Dictionary solved the problem, it added unnecessary code and computation in the form of a check for existence and an unnecessary memory comsumption for storing an extra unused value for every entry. Whereas a HashSet saves us both memory and computation. Using the right type for the problem at hand is always a good thing and becomes even more important and possibly even critical as the number of elements increase.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2014/04/angularjs-eventbus/</guid><link>http://www.johanilsson.com/2014/04/angularjs-eventbus/</link><a10:author><a10:name /></a10:author><category>AngularJs</category><category>Javascript</category><title>AngularJs EventBus</title><description>&lt;p&gt;This post introduces the EventBus functionality of angularjs and explains two ways of using it.&lt;/p&gt;
</description><pubDate>Tue, 08 Apr 2014 23:00:00 Z</pubDate><a10:updated>2014-04-08T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;A hidden little gem of angularjs is its bultin &lt;em&gt;EventBus&lt;/em&gt; functionality.
Messages can be passed between controllers with ease.
There is currently two ways of passing messages: &lt;strong&gt;Broadcast&lt;/strong&gt; and &lt;strong&gt;Emit&lt;/strong&gt;.
The difference between them is the direction the message takes in the scope hierarchy.&lt;/p&gt;

&lt;h2&gt;Using BroadCast&lt;/h2&gt;

&lt;p&gt;By using BroadCast a message is transmitted downwards to all child scopes. Every scope is a child scope of root scope and because of this, performance quickly takes a hit.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$scope.$on("EventName", function(event, data){});
$rootScope.$broadcast("EventName", data);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Using Emit&lt;/h2&gt;

&lt;p&gt;By using Emit a nessage is transmitted upwards to parent scopes. When using rootscope there is no parent scope, hence no bubbling and the standard functionality of a flat EventBus is achieved.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$rootScope.$on("EventName", function(event, data){});
$rootScope.$emit("EventName", data);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Example Using Emit&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;script src="http://code.angularjs.org/1.2.15/angular.js"&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;

&amp;lt;body ng-app="MessageBusApp"&amp;gt;
    &amp;lt;div ng-controller="MainCtrl"&amp;gt;
        Name: &amp;lt;span&amp;gt;{{ConfiguredName}}&amp;lt;/span&amp;gt;
        &amp;lt;br/&amp;gt;

        &amp;lt;div ng-controller="ChildCtrl"&amp;gt;
            Set Name: &amp;lt;input type="text" ng-model="Name"/&amp;gt; &amp;lt;button ng-click="Go(Name)"&amp;gt;Go!&amp;lt;/button&amp;gt;
        &amp;lt;/div&amp;gt;
    &amp;lt;/div&amp;gt;

    &amp;lt;script type="text/javascript"&amp;gt;
    angular.module("MessageBusApp", [])
        .controller("MainCtrl", function ($rootScope, $scope) {
            $rootScope.$on('SayHello', function (event, name) {
                $scope.ConfiguredName=name;
            });
        })
        .controller("ChildCtrl", function ($rootScope, $scope) {
            $scope.Go = function (name) {
                $rootScope.$emit('SayHello', name);
            }
        });
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Since a flat EventBus is faster than potential propagation through child scopes, &lt;strong&gt;Emit is the recommended way&lt;/strong&gt;.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2013/12/making-angularjs-directives-re-usable-by-passing-parameters/</guid><link>http://www.johanilsson.com/2013/12/making-angularjs-directives-re-usable-by-passing-parameters/</link><a10:author><a10:name /></a10:author><category>AngularJs</category><category>Javascript</category><title>Making angularjs directives re-usable by "Passing parameters"</title><description>&lt;p&gt;A look at the techniques available for building re-usable angularjs directives.&lt;/p&gt;
</description><pubDate>Tue, 17 Dec 2013 00:00:00 Z</pubDate><a10:updated>2013-12-17T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;To make software components re-usable, it's required that no data be hard-coded. This can be achieved by passing parameters. There are different ways to do this and in angularjs directives one way is by binding variables to the scope. There are three different ways to bind, so called "Binding strategies". They are the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@ : Binds to the value as a string
= : Binds to a property
&amp;amp; : Binds to a function that can be called later
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If binding from and to the same name, the name can be omitted like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name: '@name'
name: '@
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I've created a menu directive which we will refactor into utilizing all of these binding techniques. The menu has some hard-coded values namely &lt;em&gt;a title, two menu items with a text and a url, and an action that triggers when clicking an item.&lt;/em&gt; The example is structured into four components, a view, a controller, a directive and a template. We will only be modifying the view, controller and directive in this example. Starting out they look like the following:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;View:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div ng-controller="AngularMenuCtrl"&amp;gt;
    &amp;lt;menu /&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Controller:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.controller('AngularMenuCtrl', function () {
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Template:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class="menu"&amp;gt;
    &amp;lt;span&amp;gt;{{title}}&amp;lt;/span&amp;gt;
    &amp;lt;ul&amp;gt;
        &amp;lt;li ng-repeat="item in items" 
            ng-class="{selected: $index==selectedIndex}" 
            ng-click="Click($index)"&amp;gt;{{item.Text}}&amp;gt;
        &amp;lt;/li&amp;gt;
    &amp;lt;/ul&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Directive:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.directive("menu", function () {
    return {
        restrict: 'E',
        templateUrl: '/Menu.html',
        link: function (scope) {
            scope.title= 'Menu';

            scope.items= [
                    { Text: 'Item 1', Value: 'Url1' },
                    { Text: 'Item 2', Value: 'Url2' }
            ];

            scope.Click = function (index) {
                scope.selectedIndex = index;
                alert("Transitioning to " + scope.items[index].Value);
            };
         }
     };
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's start off with having the title be specified in the view by adding an html attribute called &lt;strong&gt;title&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;menu title="Menu"/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then remove the title assignment in the link function of our directive. And add the scope object to our directive and bind the title property to the string representation of our html attribute 
&lt;em&gt;title&lt;/em&gt; using the &lt;strong&gt;@&lt;/strong&gt; binding. Remember that &lt;strong&gt;since we bind the html attribute 'title' to the directives' scope property 'title', we can omit the name and just use @ instead of @title&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.directive("menu", function () {
    return {
        restrict: 'E',
        templateUrl: '/Menu.html',
        scope: { title: '@' },
        link: function (scope) {
            scope.items= [
                    { Text: 'Item 1', Value: 'Url1' },
                    { Text: 'Item 2', Value: 'Url2' }
            ];
            scope.Click = function (index) {
                scope.selectedIndex = index;
                alert("Transitioning to " + scope.items[index].Value);
            };
         }
     };
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since the menu entries will almost always be different, let's go ahead and make them configurable by moving them to our menu controller. That way different menus can have different surrounding menu controllers. We'll do this by introducing a scope property named &lt;em&gt;items&lt;/em&gt; and bind our html attribute with the same name to this new property. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;menu title="Menu" items="items"/&amp;gt;

module.controller('AngularMenuCtrl', function ($scope) {
     $scope.items = [
           { Text: 'Item 1', Value: 'Url1' },
           { Text: 'Item 2', Value: 'Url2' }];
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then bind this new attribute to our directives' scope using &lt;strong&gt;=&lt;/strong&gt;. And also remove the existing hard-coded menu items in the directive.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.directive("menu", function () {
    return {
        restrict: 'E',
        templateUrl: '/Menu.html',
        scope: {
            title: '@',
            items: '='
        },
        link: function (scope) { 
            scope.Click = function (index) {
                scope.selectedIndex = index;
                alert("Transitioning to " + scope.items[index].Value);
            };
         }
     };
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With two out of three objectives achieved the only thing left in our example is the hard-coded click functionality. For the click functionality we want the selection of the active menu item (and any other core menu functionality) to be re-used and at the same time allow for some custom user specified functionality to be run (in our case: alerting which url we are transitioning to).&lt;/p&gt;

&lt;p&gt;Let's take the same approach we took for our menu items: We first create an &lt;em&gt;AlertTransition&lt;/em&gt; function on the controller scope and move the alert functionality over from the directive:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.controller('AngularMenuCtrl', function ($scope) {

    $scope.items = [
           { Text: 'Item 1', Value: 'Url1' },
           { Text: 'Item 2', Value: 'Url2' }
    ];

    $scope.AlertTransition = function(index) {
        alert("Transitioning to " + $scope.items[index].Value);
    };
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then bind this in our view, but note that this time the name of the html attribute and scope property are not the same, showing that they can be different.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;menu title="Menu" items="items" click="AlertTransition(index)"/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then bind the click html attribute to our directives' scope using the &lt;strong&gt;&amp;amp;&lt;/strong&gt; binding. This will pass a reference to a function to our directive that we can then invoke in our menu click function. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   app.directive("menu", function () {
    return {
        restrict: 'E',
        templateUrl: '/Menu.html',
        scope: {
            title: '@',
            items: '=',
            click: '&amp;amp;'
        },
        link: function (scope) {
            scope.Click = function (index) {
                scope.selectedIndex = index;
                scope.click({ index: index });
            };
        }
    };
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One tricky thing when invoking a function bound using &lt;strong&gt;&amp;amp;&lt;/strong&gt;, is that the parameters have to be passed in the form of an object:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{ parameterName: value }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And with this last step we have a fully working Menu directive ready for re-use :)&lt;br /&gt;
&lt;a href="https://github.com/Dashue/Blogging/tree/master/Making_angularjs_directives_re_usable_by_passing_parameters"&gt;Get the code for this sample&lt;/a&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2013/12/locking-made-easy/</guid><link>http://www.johanilsson.com/2013/12/locking-made-easy/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>Locking made easy</title><description>&lt;p&gt;Locking is hard, here is one solution to making it less so.&lt;/p&gt;
</description><pubDate>Fri, 06 Dec 2013 00:00:00 Z</pubDate><a10:updated>2013-12-06T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;With todays increase in multithreaded solutions locking are more and more often becoming a requirement. Without a clear seperation between business code and locking code it's very easy to get locking wrong and end up with an tangled mess of code.&lt;/p&gt;

&lt;p&gt;The most common issues I've seen with locking solutions are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Having a Shared syncroot for multiple non-related data
&lt;ul&gt;
&lt;li&gt;Can lead to unnecessary and costly synchronization&lt;/li&gt;
&lt;li&gt;Can lead to deadlocks&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Having no visibility where locks are retrieved or set (i.e locks are acquired in multiple locations)
&lt;ul&gt;
&lt;li&gt;Leads to hard to read code&lt;/li&gt;
&lt;li&gt;Can lead to deadlocks&lt;/li&gt;
&lt;li&gt;Can lead to unlocked access of data &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So to remedy this, I came up with a simple piece of base that I call LockBase:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private readonly object _syncRoot;

    public LockBase()
    {
        _syncRoot = new object();
    }

    public void WithLock(Action action)
    {
        lock (_syncRoot)
        {
            action.Invoke();
        }
    }

    public T WithLock&amp;lt;T&amp;gt;(Func&amp;lt;T&amp;gt; action)
    {
        lock (_syncRoot)
        {
            return action.Invoke();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I'm mostly using this to build specific caches. Something along the lines of this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class MyCache : LockBase
{
    private Dictionary&amp;lt;int, string&amp;gt; _cache = new Dictionary&amp;lt;int, string&amp;gt;();

    public string Get(int key)
    {
        return WithLock(() =&amp;gt; _cache[key]);
    }

    public void Set(int key, string value)
    {
        WithLock(() =&amp;gt; _cache[key] = value);
    }

    public bool Contains(int key)
    {
        return WithLock(() =&amp;gt; _cache.ContainsKey(key));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hope it helps&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2013/11/configurationsection-a-testable-and-dependable-configuration-solution/</guid><link>http://www.johanilsson.com/2013/11/configurationsection-a-testable-and-dependable-configuration-solution/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>ConfigurationSection "A testable, dependable configuration solution"</title><description>&lt;p&gt;Most every application and service needs configuration of some sort. This post explains an approach that offers testability.&lt;/p&gt;
</description><pubDate>Mon, 25 Nov 2013 00:00:00 Z</pubDate><a10:updated>2013-11-25T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I wanted to share a way of handling application configuration that have helped me alot. It leverages &lt;a href="http://msdn.microsoft.com/en-us/library/system.configuration.configurationsection(v=vs.110).aspx"&gt;ConfigurationSection&lt;/a&gt; and gives you the possiblility to test-drive your application settings. Let's jump in!&lt;/p&gt;

&lt;h2&gt;The basic scenario&lt;/h2&gt;

&lt;p&gt;Given an App.Config file with the following contents. (&lt;strong&gt;Make sure you align the type property to your solution&lt;/strong&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;configSections&amp;gt;
        &amp;lt;section name="MyConfiguration" type="My.Namespace.MyConfiguration, My.Assembly"/&amp;gt;
    &amp;lt;/configSections&amp;gt;

    &amp;lt;MyConfiguration Age="25" Name="Name" DayOfBirth="Monday" /&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In tdd fashion, let's start out with the test. Normally I would add one property at a time to get a short red-green cycle, but for the sake of keeping down the size of this post we will add all of them at once.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void ReadMyConfiguration()
{
    IMyConfiguration configuration = MyConfiguration.Get();

    Assert.Equal(25, configuration.Age);
    Assert.Equal("Name", configuration.Name);
    Assert.Equal(DayOfWeek.Monday, configuration.DayOfBirth);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For demonstration purpose we read a number, a string and an enumeration. Let's go ahead and specify what will be our contract: IMyConfiguration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public interface IMyConfiguration
{
    int Age { get; }
    string Name { get; }
    DayOfWeek DayOfBirth { get; }

    IEnumerable&amp;lt;string&amp;gt; MyStrings { get; }
    List&amp;lt;ConnectionEntry&amp;gt; MyConnections { get; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Heading back to the test we see that the only thing left to implement is the MyConfiguration class. Let's add the following implementation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class MyConfiguration : ConfigurationSection, IMyConfiguration
{
    private MyConfiguration() {}

    public static IMyConfiguration Get()
    {
        return (IMyConfiguration)ConfigurationManager.GetSection("MyConfiguration");
    }

    [ConfigurationProperty("Age", IsRequired = true)]
    public int Age
    {
        get
        {
            return (int)this["Age"];
        }
    }

    [ConfigurationProperty("Name", IsRequired = true)]
    public string Name
    {
        get
        {
            return (string)this["Name"];
        }
    }

    [ConfigurationProperty("DayOfBirth", IsRequired = true)]
    public DayOfWeek DayOfBirth
    {
        get
        {
            return (DayOfWeek)this["DayOfBirth"];
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We make the default constructor private to expose only one way of instantiating the class. This step should leave you with a passing test.&lt;/p&gt;

&lt;h2&gt;Enums&lt;/h2&gt;

&lt;p&gt;Did you notice how cleanly the enumeration was supplied to us, no explicit calls to TryParse needed. What's also nice is that we get descriptive feedback if we were to misstype the value of an enum. For example changing the DateOfBirth to be misspellt "Mnoday" gives the following exception:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The value of the property 'DayOfBirth' cannot be parsed. 
The error is: The enumeration value must be one of the following: 
Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Required&lt;/h2&gt;

&lt;p&gt;We will also be given an exception for any missing properties that are marked as required.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Required attribute 'Age' not found.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Moving on to the marginally more advanced stuff&lt;/h2&gt;

&lt;h2&gt;Multiple Values&lt;/h2&gt;

&lt;p&gt;Sometimes storing and fetching individual values are not enough and the usage of lists of values are required. Leveraging the configuration section approach makes it really simple.&lt;/p&gt;

&lt;p&gt;The following is my preferred way of storing multiple values, it's quick and simple.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;MyConfiguration MyStrings="value1,value2,value3" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ConfigurationProperty("MyStrings", IsRequired = true)]
[TypeConverter(typeof(CommaDelimitedStringCollectionConverter))]
public IEnumerable&amp;lt;string&amp;gt; MyStrings
{
    get
    {
        return ((CommaDelimitedStringCollection)this["MyStrings"]).Cast&amp;lt;string&amp;gt;();
    }
}

Assert.Equal(3, configuration.MyStrings.Count());
Assert.Equal("Value1", configuration.MyStrings.ElementAt(0));
Assert.Equal("Value2", configuration.MyStrings.ElementAt(1));
Assert.Equal("Value3", configuration.MyStrings.ElementAt(2));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A bit more advanced approach can be used when wanting to store a list of entries with multiple values. This is done accordingly:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Connections&amp;gt;
  &amp;lt;add Server="Server1" Port="80"/&amp;gt;
  &amp;lt;add Server="Server2" Port="88"/&amp;gt;
&amp;lt;/Connections&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ConfigurationProperty("Connections", IsRequired = true)]
public ConnectionCollection ConnectionCollection
{
    get { return ((ConnectionCollection)this["Connections"]); }
}

public List&amp;lt;ConnectionEntry&amp;gt; MyConnections
{
    get { return ConnectionCollection.Cast&amp;lt;ConnectionEntry&amp;gt;().ToList(); }
}

public class ConnectionCollection : ConfigurationElementCollection
{
    protected override ConfigurationElement CreateNewElement()
    {
        return new ConnectionEntry();
    }

    protected override object GetElementKey(ConfigurationElement element)
    {
        return ((ConnectionEntry)element).Server;
    }
}

public class ConnectionEntry : ConfigurationElement
{
    [ConfigurationProperty("Server", IsRequired = true)]
    public string Server
    {
        get { return (string)this["Server"]; }
    }

    [ConfigurationProperty("Port", IsRequired = true)]
    public int Port
    {
        get { return (int)this["Port"]; }
    }
}

Assert.Equal(2, configuration.MyConnections.Count);
Assert.Equal("Server1", configuration.MyConnections[0].Server);
Assert.Equal(80, configuration.MyConnections[0].Port);
Assert.Equal("Server2", configuration.MyConn
ections[1].Server);
Assert.Equal(88, configuration.MyConnections[1].Port);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;TypeConverters&lt;/h2&gt;

&lt;p&gt;Did you notice the use of the TypeConverter of type &lt;strong&gt;CommaDelimitedStringCollectionConverter&lt;/strong&gt; in the previous example? This is just one of many converters provided by the framework. The following is a list of all the converters I was able to find. I'll leave it up to you to tinker around and figure out which ones can be useful to your configurations.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ArrayConverter&lt;/li&gt;
&lt;li&gt;BooleanConverter&lt;/li&gt;
&lt;li&gt;ByteConverter&lt;/li&gt;
&lt;li&gt;CharConverter&lt;/li&gt;
&lt;li&gt;CollectionConverter&lt;/li&gt;
&lt;li&gt;CommaDelimitedStringCollectionConverter&lt;/li&gt;
&lt;li&gt;ComponentConverter&lt;/li&gt;
&lt;li&gt;CultureInfoConverter&lt;/li&gt;
&lt;li&gt;DateTimeConverter&lt;/li&gt;
&lt;li&gt;DateTimeOffsetConverter&lt;/li&gt;
&lt;li&gt;DecimalConverter&lt;/li&gt;
&lt;li&gt;DoubleConverter&lt;/li&gt;
&lt;li&gt;EnumConverter&lt;/li&gt;
&lt;li&gt;ExpandableObjectConverter&lt;/li&gt;
&lt;li&gt;ExtendedProtectionPolicyTypeConverter&lt;/li&gt;
&lt;li&gt;GenericEnumConverter&lt;/li&gt;
&lt;li&gt;GuidConverter&lt;/li&gt;
&lt;li&gt;InfiniteIntConverter&lt;/li&gt;
&lt;li&gt;InfiniteTimeSpanConverter&lt;/li&gt;
&lt;li&gt;Int16Converter&lt;/li&gt;
&lt;li&gt;Int32Converter&lt;/li&gt;
&lt;li&gt;Int64Converter&lt;/li&gt;
&lt;li&gt;MultilineStringConverter&lt;/li&gt;
&lt;li&gt;NullableConverter&lt;/li&gt;
&lt;li&gt;ReferenceConverter&lt;/li&gt;
&lt;li&gt;SByteConverter&lt;/li&gt;
&lt;li&gt;SingleConverter&lt;/li&gt;
&lt;li&gt;StringConverter&lt;/li&gt;
&lt;li&gt;TimeSpanConverter&lt;/li&gt;
&lt;li&gt;TimeSpanMinutesConverter&lt;/li&gt;
&lt;li&gt;TimeSpanMinutesOrInfiniteConverter&lt;/li&gt;
&lt;li&gt;TimeSpanSecondsConverter&lt;/li&gt;
&lt;li&gt;TimeSpanSecondsOrInfiniteConverter&lt;/li&gt;
&lt;li&gt;TypeConverter&lt;/li&gt;
&lt;li&gt;TypeNameConverter&lt;/li&gt;
&lt;li&gt;UInt16Converter&lt;/li&gt;
&lt;li&gt;UInt32Converter&lt;/li&gt;
&lt;li&gt;UInt64Converter&lt;/li&gt;
&lt;li&gt;UriTypeConverter&lt;/li&gt;
&lt;li&gt;WhiteSpaceTrimStringConverter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://github.com/Dashue/Blogging/tree/master/ConfigurationSection_Testable_and_Maintainable"&gt;Source for this blog post can be found here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Have fun!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2013/10/migrating-to-sandra-snow/</guid><link>http://www.johanilsson.com/2013/10/migrating-to-sandra-snow/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>Opensource</category><title>Migrating To Sandra.Snow</title><description>&lt;p&gt;A story about hosting a blog on github&lt;/p&gt;
</description><pubDate>Sun, 20 Oct 2013 23:00:00 Z</pubDate><a10:updated>2013-10-20T23:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;Having tried hosting my blog on tumblr, my own wordpress instance and wordpress online I've never been really happy. To me, writing should be simple and easy, so when I first heard of Sandra.Snow: A solution to freely host your blog on github pages with full control over everything, I jumped on it!&lt;/p&gt;

&lt;p&gt;First thing I had to do was migrate my original posts (html) off of wordpress. The other people using Sandra.Snow that I know of created a Wordpress export file and manually started to migrate posts over. I on the other hand claimed "Why spend 2 hours of manual labour when I can spend two weeks to automate the process". In hindsight not the best approach :) , but from it were two open source solutions born:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.nuget.org/packages/HtmlToMarkdown.Net/"&gt;Html To Markdown.Net&lt;/a&gt;  &lt;em&gt;(Apparently this didn´t exist already)&lt;/em&gt;&lt;br /&gt;
&lt;a href="https://github.com/Dashue/FromWordpressToSandraSnow"&gt;From Wordpress To Sandra.Snow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So in the following days I will continue to sanity-check old posts and publish them here.&lt;br /&gt;
Sandra.Snow: &lt;a href="https://github.com/Sandra/Sandra.Snow"&gt;Github&lt;/a&gt; &lt;a href="https://jabbr.net/#/rooms/SandraSnow"&gt;Jabbr&lt;/a&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/02/a-few-caveats-when-using-strings-in-net/</guid><link>http://www.johanilsson.com/2012/02/a-few-caveats-when-using-strings-in-net/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>A few caveats when using Strings in .Net</title><description>&lt;p&gt;String induced garbage collection&lt;/p&gt;
</description><pubDate>Thu, 23 Feb 2012 00:00:00 Z</pubDate><a10:updated>2012-02-23T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;Strings in .Net are class objects and unlike value types they are stored on the heap.&lt;/p&gt;

&lt;p&gt;According to msdn: &lt;a href="http://msdn.microsoft.com/en-us/library/ee787088.aspx"&gt;http://msdn.microsoft.com/en-us/library/ee787088.aspx&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Garbage collection occurs when one of the following conditions is true:&lt;/p&gt;
  
  &lt;ul&gt;
  &lt;li&gt;The system has low physical memory.&lt;/li&gt;
  &lt;li&gt;The memory that is used by allocated objects on the managed heap surpasses an acceptable threshold. This means that a threshold of acceptable memory usage has been exceeded on the managed heap. This threshold is continuously adjusted as the process runs.&lt;/li&gt;
  &lt;li&gt;The GC.Collect  method is called. In almost all cases, you do not have to call this method, because the garbage collector runs continuously. This method is primarily used for unique situations and testing.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Due to the second condition creating a string object can trigger garbage collection, which is costly in terms of performance. As developers we want to keep the string creation to a minimum. Since strings in .Net are immutable (manipulation results in a the creation of a new instance) means that combining two strings "string1" + "string2" results in the creation of three strings and editing a string results in creating a new one with the modification.&lt;/p&gt;

&lt;p&gt;I think it's good to have the knowledge about how things work and why even though it's considered an micro optimization.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/02/why-youd-want-to-place-a-shared-library-in-its-own/</guid><link>http://www.johanilsson.com/2012/02/why-youd-want-to-place-a-shared-library-in-its-own/</link><a10:author><a10:name /></a10:author><category>Software Development</category><title>Why you'd want to place a shared library in its own solution</title><description>&lt;p&gt;First consumer, second consumer or separate solution, that is the question?&lt;/p&gt;
</description><pubDate>Sat, 18 Feb 2012 00:00:00 Z</pubDate><a10:updated>2012-02-18T00:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;A situation occurred on work where we decided to refactor duplicated funtionality from two project (A and B) into a new shared library (X) DRYing things up. During this process the question of where to put X came up. I quickly answered "It's own solution" whereupon my colleague countered with the very simple yet valid question "Why" and I realized I didn't have the answer. I know it was really obvious but I had never reflected on the why.&lt;/p&gt;

&lt;p&gt;After work I decided to gather my thoughts and write this blog giving a better answer to his valid question.&lt;/p&gt;

&lt;h2&gt;Presumptions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;We will use internal Nuget feed for the library.&lt;/li&gt;
&lt;li&gt;X could be placed in either A or B or separate library.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Consuming the Library&lt;/h2&gt;

&lt;p&gt;Placing it in its own solution forces all projects consume it the same way, otherwise some projects would use nuget and one could use project reference. &lt;/p&gt;

&lt;h2&gt;Future Changes&lt;/h2&gt;

&lt;p&gt;If placed in A it would be easy to change according to requirement or quick fix for A and not think about B or any future consumers. Placing it in its own solution forces it to behave more like an independent library and less like a project reference. It makes more sense to open the solution for the library when change is needed than to open an unrelated solution containing the library.&lt;/p&gt;

&lt;h2&gt;Unrelated Functionality&lt;/h2&gt;

&lt;p&gt;Since the functionality is general and not related to neither A nor B, placing it in the same solution just because it's consumed by them is not a valid argument.&lt;/p&gt;

&lt;h2&gt;Versioning&lt;/h2&gt;

&lt;p&gt;The library has different release/deploy cycles than the consumers and using Nuget allows for choosing what version and if/when to upgrade. Different consumers can easily consume different versions of the library. &lt;/p&gt;

&lt;h2&gt;YAGNI&lt;/h2&gt;

&lt;p&gt;YAGNI was mentioned as an argument against placing X in its own library. I think developers are to fast to throw abbreviations as arguments thinking they are valid without actually considering the situation at hand.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/01/photoutil-v1-0-0-1-aka-speeding-up-a-c-project/</guid><link>http://www.johanilsson.com/2012/01/photoutil-v1-0-0-1-aka-speeding-up-a-c-project/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>Opensource</category><category>Pet Project</category><title>PhotoUtil v1.0.0.1 aka Speeding up a c# project</title><description>&lt;p&gt;My media organizing pet project was running a bit slow. This is how I was able to analyze, identify and solve the biggest bottleneck using visual studios performance wizard.&lt;/p&gt;
</description><pubDate>Wed, 25 Jan 2012 00:00:00 Z</pubDate><a10:updated>2012-01-25T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I was investigating why my hobby project &lt;a href="https://github.com/Dashue/MediaOrganizer"&gt;"PhotoUtil"&lt;/a&gt; was being slow.
A program that takes a folder with a bunch of photos as inputs, processes the metadata from them, more specifically the date the picture was taken and then organizes them in folders based on this.&lt;/p&gt;

&lt;p&gt;Following is a short recap of that procedure.&lt;/p&gt;

&lt;h2&gt;Find out what's taking time 1: Analyze / Launch Performance Wizard&lt;/h2&gt;

&lt;p&gt;The first thing that popped out at me was a DateTime creation which took 100% of the CPU time (according to the performance report). I grab the DateTimeOriginal value from exif metadata of a photo and convert it into datetime, only because it allowed for cleaner code when accessing the date and time values later on in the code. Apparently parsing strings into datetime is slow, so instead I got it to work with some string manipulation.&lt;/p&gt;

&lt;h2&gt;Find out what's taking time 2: Analyze / Launch Performance Wizard&lt;/h2&gt;

&lt;p&gt;When reading exif data using GDI+ from a file the whole image is read into memory using new Bitmap(Path); then the desired properties are fetched using GetProperty. This made me switch focus to increasing concurrent files being worked on (read parallelization) instead of minimizing process time of each file. With this in mind I rewrote my foreach loop into using the parallel library.&lt;/p&gt;

&lt;p&gt;from&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;foreach(var filepath in filepaths)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Parallel.ForEach(filePaths, oldFilePath); 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Taking it one step further:&lt;/h2&gt;

&lt;p&gt;After finding out that the whole image is read into memory I set out to find an alternate approach of extracting EXIF data from a photo. It wasn't long before I found a sweet project called &lt;a href="http://www.codeproject.com/Articles/36342/ExifLib-A-Fast-Exif-Data-Extractor-for-NET-2-0"&gt;ExifLib&lt;/a&gt; on &lt;a href="https://www.nuget.org/packages/ExifLib/"&gt;Nuget&lt;/a&gt; which only reads the Exif data portion of an image. ExifLib is a wonderful lib created by Simon McKenzie only available as source code from codeproject.com but I'm hoping to convince him to put it up on NuGet so more people can find and make use of it.&lt;/p&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;100 images processed on an Intel Core 2 duo&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Before optimizations:   00:00:20.8059121  
After optimizations:    00:00:11:4034511
Using ExifLib:          00:00:01.0714248
&lt;/code&gt;&lt;/pre&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/01/review-tfs-11-the-things-i-look-forward-to/</guid><link>http://www.johanilsson.com/2012/01/review-tfs-11-the-things-i-look-forward-to/</link><a10:author><a10:name /></a10:author><category>Software Development</category><title>Review TFS 11: The things I look forward to</title><description>&lt;p&gt;With TFS 11 around the corner I compiled this list of featuers that will solve my biggest issues with the previous versions.&lt;/p&gt;
</description><pubDate>Fri, 13 Jan 2012 00:00:00 Z</pubDate><a10:updated>2012-01-13T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;TFS 11 (with in-place upgrade from 2010), having been rewritten with the promise of a faster and smarter experience &lt;/p&gt;

&lt;p&gt;These are the features I look forward to the most.&lt;/p&gt;

&lt;h2&gt;Automerge content changes (finally)&lt;/h2&gt;

&lt;p&gt;Finally TFS has come to it&amp;#8217;s senses and allows for automerge of non-conflicting content changes. &lt;/p&gt;

&lt;h2&gt;My work pane and Search work items&lt;/h2&gt;

&lt;p&gt;No need for custom work item queries, work related to you will be easily available in the work item pane. Searching for items is also available here.&lt;/p&gt;

&lt;h2&gt;Easier to transition between work items states&lt;/h2&gt;

&lt;p&gt;No more open work item and changing state to in progress, just right-click item in my work pane and click start.&lt;/p&gt;

&lt;h2&gt;Suspending&lt;/h2&gt;

&lt;p&gt;Easier task switching by using suspend/resume. Saves visual studio state, open files and position in currently open file. Suspended tasks are listed in you work pane.&lt;/p&gt;

&lt;h2&gt;New Pending changes page&lt;/h2&gt;

&lt;p&gt;Shows tree of pending changes. Allows or leaving files in excluded state without having to exclude changes every check-in (good for personalized web.config etc.).&lt;/p&gt;

&lt;h2&gt;New built-in diff tool&lt;/h2&gt;

&lt;p&gt;TFS team has finally gotten around to fix the built in diff tool, which now supports more view modes and reflects live changes. Which means diff will update if you make changes to your version when showing base/yours. The merge tool has also gotten some love.&lt;/p&gt;

&lt;h2&gt;Local workspaces&lt;/h2&gt;

&lt;p&gt;Removes offline mode, and the time out method require to go offline. Doesn&amp;#8217;t handle modified files by reading the read-only bit on the file (Took them until 2012 to fix it). File system watcher watch for change made outside of VS, and lists them nicely in the pending changes pane.&lt;/p&gt;

&lt;h2&gt;Shelving&lt;/h2&gt;

&lt;p&gt;Shelveset merge (with current and baseless) and searching of shelvesets.&lt;/p&gt;

&lt;h2&gt;Code Review workflow&lt;/h2&gt;

&lt;p&gt;Request code-review workflow on suspended changeset or checked in changeset as well as code reviewing functionality with the ability to comment on specific changes and even alter the changeset.&lt;/p&gt;

&lt;h2&gt;Rollback changesets&lt;/h2&gt;

&lt;p&gt;Awesome&lt;/p&gt;

&lt;h2&gt;Async operations&lt;/h2&gt;

&lt;p&gt;Modality and blocking operations has now been removed, no more waiting on visual studio to complete retrieving things (search items etc.).&lt;/p&gt;

&lt;h2&gt;New Builds page&lt;/h2&gt;

&lt;p&gt;Shows builds associated to me (started by me etc.). Extensible&lt;/p&gt;

&lt;h2&gt;Summary:&lt;/h2&gt;

&lt;p&gt;I really like the new way that TFS 11 shows data; putting the concept of "My work" in focus, showing my work items and my builds etc. This combined with the new functionalities provided, working in TFS 11 will be much more smother and faster than it's predecessors and I am really looking forward til it's released and part of my development environment.&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href="http://channel9.msdn.com/Events/BUILD/BUILD2011/TOOL-811T"&gt;Developer collaboration with Team Foundation Server 11&lt;/a&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/01/enumerable-zip/</guid><link>http://www.johanilsson.com/2012/01/enumerable-zip/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>Enumerable.Zip</title><description>&lt;p&gt;Found an Linq operator that I cannot understand the need for.&lt;/p&gt;
</description><pubDate>Thu, 12 Jan 2012 00:00:00 Z</pubDate><a10:updated>2012-01-12T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I just stumbled upon Enumerable.Zip which is a newly added Linq operator since .NET Framework 4.&lt;/p&gt;

&lt;p&gt;Signature is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static IEnumerable&amp;lt;TResult&amp;gt; Zip&amp;lt;TFirst, TSecond, TResult&amp;gt;(
    this IEnumerable&amp;lt;TFirst&amp;gt; first,
    IEnumerable&amp;lt;TSecond&amp;gt; second,
    Func&amp;lt;TFirst, TSecond, TResult&amp;gt; func);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much like a zipper it "zips" together two IEnumerables applying a specified function over each pair of elements.
I've seen examples which print the greater number from two list of ints, which constructs addresses from four lists of city/street/number/flatnumber and one that prints name and age from name/age lists.&lt;/p&gt;

&lt;p&gt;I have as of yet found a good real world example, and am incapable of thinking one up.&lt;br /&gt;
Anyone out there who have made good use of this added functionality?&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2012/01/my-take-on-ref/</guid><link>http://www.johanilsson.com/2012/01/my-take-on-ref/</link><a10:author><a10:name /></a10:author><category>.Net</category><category>Software Development</category><title>My take on Ref</title><description>&lt;p&gt;A good friend of mine asked me to share my thoughts on the ref keyword&lt;/p&gt;
</description><pubDate>Wed, 11 Jan 2012 00:00:00 Z</pubDate><a10:updated>2012-01-11T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;A good friend of mine asked me to share my thoughts on the ref keyword so here goes.&lt;/p&gt;

&lt;p&gt;To give it some context: To me a good method is a function taking a variable amount of parameters, making some processing and possibly returning the result. Furthermore the method should do one thing and one thing only and never change input parameter values.&lt;/p&gt;

&lt;p&gt;Now the ref keyword allow developers to stray from this "ideal" method by allowing it to change the values of the input parameters. Obfuscating the self-documentation of the method and by this diffusing what the method does and what it's single responsibility is. This creates a required understanding by your fellow colleagues about the intricates of the method, and in turn requires every developer to know how every method in the system is implemented.&lt;/p&gt;

&lt;p&gt;The most common reason for using ref parameters is simply that your method is doing to much, rendering you unable to return a single value/collection to account for everything that is being done, ending up with sending and object as input parameter and changing a lot of values. This may be improved by returning part of the data as an out parameter and part of it as the return value if possible.&lt;/p&gt;

&lt;p&gt;The reason why I think that using out is better than ref is because out doesn't obfuscate the api and the intention of the method. Using Ref conveys that "This method might(?) change values of the parameter or even the parameter itself" while Out conveys that "This method will change the parameter".&lt;/p&gt;

&lt;p&gt;Consider these two implementations of this contrived example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Example 1: Returning value
Assert.AreEqual(4, Square(2));

Example 2: Using Ref
float a = 2;  
Square(a);  
Assert.AreEqual(4, a);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I would like to end this post with my oppinion on the "Ref" and "Out" keywords.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Although there are valid cases when the right solution is to use Ref and Out, from my experince I say you rarely need to use Out, and you need a really good reason for using Ref.&lt;/p&gt;
&lt;/blockquote&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2011/12/learning-steps-for-design-patterns-from-dnrtv-194/</guid><link>http://www.johanilsson.com/2011/12/learning-steps-for-design-patterns-from-dnrtv-194/</link><a10:author><a10:name /></a10:author><category>Software Development</category><title>The 4 stages of learning a design pattern</title><description>&lt;p&gt;Was watching dnrTV:194 the other day with Steve Smith on Commonly Used Design Patterns. He explained the 4 stages of learning a design pattern and I would like to share that here.&lt;/p&gt;
</description><pubDate>Fri, 09 Dec 2011 00:00:00 Z</pubDate><a10:updated>2011-12-09T00:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Stage 0 - Ignorance&lt;/h2&gt;

&lt;p&gt;You used what? Never heard of it.&lt;/p&gt;

&lt;h2&gt;Stage 1 - Awakening&lt;/h2&gt;

&lt;p&gt;Wow, I just learned how XYZ pattern can improve my design. I'm not really sure where it would work in my code, but I'm definitely looking.&lt;/p&gt;

&lt;h2&gt;Stage 2 - Overzealous&lt;/h2&gt;

&lt;p&gt;I totally "get" the XYZ pattern; I'm adding it everywhere I can shoehorn it into m code. My design's gonna be better now, for sure!&lt;/p&gt;

&lt;h2&gt;Stage 3 - Mastery&lt;/h2&gt;

&lt;p&gt;After allowing the design to evolve through interaction with the users and the addition of tests, it started to exhibit ABC negative characteristics, but the XYZ pattern was a logical next step and was achieved through a simple refactoring.   &lt;/p&gt;

&lt;p&gt;Heard on &lt;a href="http://www.dnrtv.com/default.aspx?showNum=194"&gt;dnrTV 194 Steve Smith on Commonly Used Design Patterns&lt;/a&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2011/11/technical-debt-101/</guid><link>http://www.johanilsson.com/2011/11/technical-debt-101/</link><a10:author><a10:name /></a10:author><category>Software Development</category><title>Technical debt 101</title><description>&lt;p&gt;An introduction to technical debt, what it is, why you care, how to find it, remove it and prevent it from growing out of control.&lt;/p&gt;
</description><pubDate>Thu, 10 Nov 2011 00:00:00 Z</pubDate><a10:updated>2011-11-10T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I would like to start this article with the definition of what technical debt is. Technical debt is taking shortcuts for good or bad, for known or unknown reasons. The technical debt grows exponentially over time because of interest. &lt;/p&gt;

&lt;h2&gt;Interest:&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Every minute spent on not-quite-right code counts as interest on that debt - Wikipedia&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The amount of interest is based on a number of things, among others:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Lack of knowledge - Either from time passing and people forget stuff, or from people changing jobs, leave of absence, death etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Increase in complexity - New functionality will be designed and implemented on top and according to existing technical debt, writing more code to get around code, with more code you need more tests and this code and tests needs review. Hence technical debt will increase technical debt.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;How to spot debt:&lt;/h2&gt;

&lt;p&gt;There are some signs to look for when you go "debt spotting&amp;amp;" to make it easier to point technical debt.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The code areas where you as a developer when assigned bugs or to extend this code feel your heart sink, your moral drop e.g spaghetti code, or unnecessary complexity, or if the intent of the code isn't clear enough so it has to use comments or regions as a crutch for relaying what it does&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The average amounts of tasks per sprint decreases&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The number of tests increases at the same time as "average amount of tasks/sprint decreases"&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With an agile project methodology you don&amp;#8217;t necessarily have a lower technical debt but because of its support for rapid changes the debt will be highlighted at an earlier stage allowing you to decide if to pay this debt or not.&lt;/p&gt;

&lt;p&gt;In my experience test driven development and tests in general protect you from some technical debt because you've had to go through the steps of "red", "green", "refactor"; and thereby paid a little of the debt up front.&lt;/p&gt;

&lt;h2&gt;Paying debt:&lt;/h2&gt;

&lt;p&gt;Like with any debt there is always an enforcer, a collector that will &lt;em&gt;make&lt;/em&gt; you pay that debt. With technical debt, this collector is usually time, or new requirements.  &lt;/p&gt;

&lt;p&gt;Because of the interest, paying the debt will be more and more expensive as time goes, until you are forced by time to pay, at its most latest stage. This is when its the most expensive to pay the debt because you are most prone to the interests of people with skills have moved on, system have changed, a lot of technical debt has been built and made dependent on underlying technical debt. The debt may even be so large so for you to be able to pay it your feature development will stagnate and may even lead to loss of market pieces.&lt;/p&gt;

&lt;p&gt;Often project managers don't allow developers to pay technical debt, or don't prioritise it since its sometimes hard to motivate a sprint that starts with 12 tasks and ends with 12 tasks still to do, with the only thing the developers salary has paid is the debt.&lt;/p&gt;

&lt;h2&gt;Types of Technical Debt:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Bugs are not technical debt until someone decides to not fix them.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Manage technical debt = planned technical debt&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unmanaged is the worst, this is only fixed when the pain is felt&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Monitoring Technical Debt:&lt;/h2&gt;

&lt;p&gt;In order to be able to monitor the debt, you must keep track of it. This involves keeping track of both the managed debt introduced on purpose using shortcuts, quick solutions and the "not-quite-right" solutions, and the unmanaged ones whenever they are encountered and grade them in some way that gives them a relational size difference. My personal view is that for every day that goes by of coding, it's very unlikely that the technical debt remains the same but instead rather if you don't pay some you gain some. Taking time into consideration, just a small daily increase will eventually become very expensive to pay off, leave it too long and a rewrite may end up being your only solution. &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Technical debt is like an iceberg with only 10 percent visible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Until next time, keep track of that 10 percent for all your life's worth : )&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2011/11/todays-refactoring-dictionary-usage/</guid><link>http://www.johanilsson.com/2011/11/todays-refactoring-dictionary-usage/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>Todays Refactoring: Dictionary usage</title><description>&lt;p&gt;Optimizing unoptimized dictionary insertions&lt;/p&gt;
</description><pubDate>Tue, 01 Nov 2011 00:00:00 Z</pubDate><a10:updated>2011-11-01T00:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;Code like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (dictionary.ContainsKey(key))
{
  dictionary[key] = value;  
}
else
{
  dictionary.Add(key, value);  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Can be substituted with the following with the same functionality:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dictionary[key] = value;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code will be cleaner, functionality will be the same and a few operations faster :P&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2011/10/implicit-operators/</guid><link>http://www.johanilsson.com/2011/10/implicit-operators/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>Implicit Operators</title><description>&lt;p&gt;Implicit operators can be used for a lot of differnet things. One usage is explained in this post: Implicit mapping between types.&lt;/p&gt;
</description><pubDate>Tue, 25 Oct 2011 23:00:00 Z</pubDate><a10:updated>2011-10-25T23:00:00Z</a10:updated><a10:content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Mapping occur in many places in applications, mostly in boundaries between layers. Mapping one type to another, be it server to client DTOs or something else, there are numerous ways of accomplishing it. &lt;/p&gt;

&lt;p&gt;Some use a static Mapper factory, some use tools like AutoMapper, my preferred way of doing it is with the use of Implicit Operators.&lt;/p&gt;

&lt;p&gt;Like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var domainModel = new DomainModel
{
    Firstname = "Firstname",
    Lastname = "Lastname"
};

ViewModel viewModel = domainModel;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What allows us to do this is something called an "Implicit Operator". Which are defined like below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private class ViewModel
{
    public string Name { get; set; }

    public static implicit operator ViewModel(DomainModel model)
    {
        return new ViewModel
        {
            Name = model.Firstname + " " + model.Lastname
        };
    }
}

private class DomainModel
{
    public string Firstname { get; set; }
    public string Lastname { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
</a10:content></item><item><guid isPermaLink="true">http://www.johanilsson.com/2011/10/brainfart-when-sorting-lists/</guid><link>http://www.johanilsson.com/2011/10/brainfart-when-sorting-lists/</link><a10:author><a10:name /></a10:author><category>.Net</category><title>Brainfart when sorting Lists</title><description>&lt;p&gt;Optimizing unoptimized sorting of a list.&lt;/p&gt;
</description><pubDate>Sun, 23 Oct 2011 23:00:00 Z</pubDate><a10:updated>2011-10-23T23:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;Just encountered this piece of code today:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Array.Sort(myList.ToArray());
foreach(var i in myList)
{ // Do something with i }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My first though was “Wait what?” Is there some hidden functionality of List.ToArray() that I have missed which only is passed onto jedi masters? Does this way of sorting perform better than just List.Sort?&lt;/p&gt;

&lt;p&gt;I had to investigate, so I wrote up this little code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var list = new List&amp;lt;int&amp;amp;gt; {9, 4, 7, 1, 2};

Array.Sort(list.ToArray());
foreach (var i in list)
{
   Console.WriteLine(i);
}

Console.ReadKey();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lo and behold the printed sequence is: 9 4 7 1 2, hence we are creating an array, sorting it then throwing it away, only to use our list in the foreach.&lt;/p&gt;

&lt;p&gt;List.Sort uses Array.Sort internally so I would dare go out on a limb and say that speed for sorting should be the same&lt;/p&gt;
</a10:content></item></channel></rss>